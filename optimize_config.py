import json
import torch
import os

def calculate_optimal_batch_size(vram_gb=140):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ batch_size Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ VRAM"""
    # ØªØ®Ù…ÛŒÙ†: Ù‡Ø± sample Ø­Ø¯ÙˆØ¯ 1-1.5GB Ø¯Ø± fp16/bf16
    # Ø¨Ø§ 140GB Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø­Ø¯Ø§Ù‚Ù„ 96 sample
    
    if vram_gb >= 140:
        return 128
    elif vram_gb >= 80:
        return 64
    elif vram_gb >= 40:
        return 32
    else:
        return 16

def create_optimized_config():
    # Ø¨Ø±Ø±Ø³ÛŒ GPU
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        print(f"ğŸ® GPU: {gpu_name}")
        print(f"ğŸ’¾ VRAM: {vram_gb:.1f} GB")
    else:
        print("âš ï¸ No GPU detected, using default config")
        vram_gb = 0
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡
    optimal_batch = calculate_optimal_batch_size(vram_gb)
    
    config = {
        "train": {
            "log_interval": 100,
            "eval_interval": 1000,
            "save_interval": 5000,
            "seed": 1234,
            "epochs": 2000,
            "learning_rate": 0.0002,
            "betas": [0.8, 0.99],
            "eps": 1e-09,
            "batch_size": optimal_batch,
            "fp16_run": False,
            "bf16_run": True if vram_gb >= 80 else False,  # BF16 Ø¨Ø±Ø§ÛŒ H100/A100
            "lr_decay": 0.999875,
            "segment_size": 8192,
            "init_lr_ratio": 1,
            "warmup_epochs": 10,
            "c_mel": 45,
            "c_kl": 1.0,
            "grad_clip_thresh": 5.0,
            "num_workers": min(32, os.cpu_count() or 8),
            "checkpoint_interval": 5000,
            "use_flash_attn": vram_gb >= 80,  # Flash Attention Ø¨Ø±Ø§ÛŒ H100/A100
        },
        "data": {
            "training_files": "filelists/train.txt",
            "validation_files": "filelists/val.txt",
            "text_cleaners": ["basic_cleaners"],
            "max_wav_value": 32768.0,
            "sampling_rate": 22050,
            "filter_length": 1024,
            "hop_length": 256,
            "win_length": 1024,
            "n_mel_channels": 80,
            "mel_fmin": 0.0,
            "mel_fmax": 11025.0,
            "add_blank": True,
            "n_speakers": 0,
            "cleaned_text": False
        },
        "model": {
            "use_mel_posterior_encoder": True,
            "use_transformer_flows": True,
            "transformer_flow_type": "fft",
            "use_spk_conditioned_encoder": False,
            "use_noise_scaled_mas": True,
            "use_duration_discriminator": True,
            "inter_channels": 256 if vram_gb >= 80 else 192,
            "hidden_channels": 256 if vram_gb >= 80 else 192,
            "filter_channels": 1024 if vram_gb >= 80 else 768,
            "n_heads": 4 if vram_gb >= 80 else 2,
            "n_layers": 8 if vram_gb >= 80 else 6,
            "kernel_size": 3,
            "p_dropout": 0.1,
            "resblock": "1",
            "resblock_kernel_sizes": [3, 7, 11],
            "resblock_dilation_sizes": [[1, 3, 5], [1, 3, 5], [1, 3, 5]],
            "upsample_rates": [8, 8, 2, 2],
            "upsample_initial_channel": 512,
            "upsample_kernel_sizes": [16, 16, 4, 4],
            "n_layers_q": 3,
            "use_spectral_norm": False,
            "use_sdp": True
        }
    }

    
    # Ù†Ø³Ø®Ù‡ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
    with open("~/vits2_pytorch/configs/vits2_persian.json", "w") as f:
        json.dump(config, f, indent=2)
    
    # Ù†Ø³Ø®Ù‡ Ø¨Ø§ ÙÙˆÙ†Ù… (Ø§Ú¯Ø± Ù†ÛŒØ§Ø² Ø§Ø³Øª)
    config_phoneme = config.copy()
    config_phoneme["data"]["training_files"] = "filelists/train_phoneme.txt"
    config_phoneme["data"]["validation_files"] = "filelists/val_phoneme.txt"
    config_phoneme["data"]["text_cleaners"] = []
    config_phoneme["data"]["cleaned_text"] = True
    
    with open("~/vits2_pytorch/configs/vits2_persian_phoneme.json", "w") as f:
        json.dump(config_phoneme, f, indent=2)
    
    print(f"\nâœ… Configs created:")
    print(f"  - ~/vits2_pytorch/configs/vits2_persian.json (batch_size={config['train']['batch_size']})")
    print(f"  - ~/vits2_pytorch/configs/vits2_persian_phoneme.json")
    
    # Ù†Ù…Ø§ÛŒØ´ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
    print(f"\nğŸ“Š Recommendations for your system:")
    print(f"  - Optimal batch size: {optimal_batch}")
    print(f"  - BF16 training: {'Yes âœ…' if config['train']['bf16_run'] else 'No'}")
    print(f"  - Flash Attention: {'Yes âœ…' if vram_gb >= 80 else 'No'}")
    print(f"  - Model size: {'Large' if vram_gb >= 80 else 'Standard'}")
    
    # ØªØ®Ù…ÛŒÙ† Ø³Ø±Ø¹Øª Ø¢Ù…ÙˆØ²Ø´
    samples_per_sec = optimal_batch * 2  # ØªØ®Ù…ÛŒÙ†ÛŒ
    total_samples = 6500  # Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª Ø´Ù…Ø§
    steps_per_epoch = total_samples / optimal_batch
    time_per_epoch = steps_per_epoch / samples_per_sec / 60  # Ø¯Ù‚ÛŒÙ‚Ù‡
    
    print(f"\nâ±ï¸ Training estimates:")
    print(f"  - Steps per epoch: {steps_per_epoch:.0f}")
    print(f"  - Time per epoch: ~{time_per_epoch:.1f} minutes")
    print(f"  - Total training time (200k steps): ~{200000/samples_per_sec/3600:.1f} hours")

if __name__ == "__main__":
    create_optimized_config()
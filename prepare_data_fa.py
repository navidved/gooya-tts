import os
import re
import random
import unicodedata
import soundfile as sf
import librosa
import numpy as np
from datasets import load_dataset
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
HF_DATASET = "navidved/approved-tts-dataset"
OUT_WAV_DIR = "data_fa/wavs"
OUT_FL_DIR = "filelists"
SR = 22050
MIN_DUR = 1.0
MAX_DUR = 15.0

os.makedirs(OUT_WAV_DIR, exist_ok=True)
os.makedirs(OUT_FL_DIR, exist_ok=True)

# Ù†Ú¯Ø§Ø´Øª Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§
ARABIC_TO_FA = {
    '\u064A': 'ÛŒ', '\u0643': 'Ú©', '\u06C0': 'Ù‡',
    '\u06CC': 'ÛŒ', '\u0649': 'ÛŒ', '\u06A9': 'Ú©'
}

PERSIAN_DIGITS = "Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹"
LATIN_DIGITS = "0123456789"
DIGIT_MAP = {ord(p): LATIN_DIGITS[i] for i, p in enumerate(PERSIAN_DIGITS)}

DIACRITICS = ''.join(chr(c) for c in range(0x064B, 0x065F+1)) + "\u0670"
DIAC_RE = re.compile(f"[{re.escape(DIACRITICS)}]")

def normalize_persian_text(text):
    """Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ"""
    text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C')
    text = ''.join(ARABIC_TO_FA.get(ch, ch) for ch in text)
    text = DIAC_RE.sub("", text)
    text = text.translate(DIGIT_MAP)
    text = text.replace("\u0640", "")
    text = text.replace("\u200c", " ")
    text = re.sub(r"\s+", " ", text).strip()
    text = re.sub(r"[Â«Â»]", "\"", text)
    text = re.sub(r'[^\u0600-\u06FF\u0020-\u007E\s]', '', text)
    return text.strip()

def main():
    print("ğŸ”„ Loading dataset from HuggingFace...")
    
    # Ù„ÙˆØ¯ Ø¨Ø¯ÙˆÙ† ØªØ¨Ø¯ÛŒÙ„ Audio
    from datasets import Features, Value
    features = Features({
        'audio': Value('string'),  # ÛŒØ§ Ù‡Ø± type Ø¯ÛŒÚ¯Ø±ÛŒ ØºÛŒØ± Ø§Ø² Audio
        'file_name': Value('string'),
        'sentence': Value('string'),
        'speaker': Value('string'),
        'duration': Value('float32'),
        'sample_rate': Value('int32')
    })
    
    try:
        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù„ÙˆØ¯ Ø¨Ø§ features Ù…Ø´Ø®Øµ
        ds = load_dataset(
            HF_DATASET, 
            split="train",
            features=features,
            use_auth_token=True
        )
    except:
        # Ø§Ú¯Ø± Ù†Ø´Ø¯ØŒ Ø¨Ø¯ÙˆÙ† features
        ds = load_dataset(HF_DATASET, split="train", use_auth_token=True)
    
    print(f"ğŸ“Š Total samples in dataset: {len(ds)}")
    
    # Ø§Ø¨ØªØ¯Ø§ ÙÙ‚Ø· metadata Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒÙ…
    print("\nğŸ” Checking dataset structure...")
    sample = ds[0]
    print(f"Sample keys: {sample.keys()}")
    print(f"Audio field type: {type(sample.get('audio'))}")
    
    samples = []
    skipped = 0
    
    print("\nğŸµ Processing samples...")
    
    for idx in tqdm(range(len(ds)), desc="Processing"):
        try:
            item = ds[idx]
            
            # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†
            text = normalize_persian_text(item["sentence"])
            
            if len(text) < 5 or len(text) > 500:
                skipped += 1
                continue
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… ÙØ§ÛŒÙ„
            file_name = item.get("file_name", f"sample_{idx}.mp3")
            
            # Ú†Ú© Ú©Ø±Ø¯Ù† duration
            duration = item.get("duration", 0)
            if duration < MIN_DUR or duration > MAX_DUR:
                skipped += 1
                continue
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª (ÙØ¹Ù„Ø§Ù‹ Ø¨Ø¯ÙˆÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª)
            samples.append({
                'idx': idx,
                'text': text,
                'file_name': file_name,
                'duration': duration
            })
            
        except Exception as e:
            print(f"\nError processing item {idx}: {e}")
            skipped += 1
            continue
    
    print(f"\nğŸ“Š Initial processing complete:")
    print(f"  - Valid samples: {len(samples)}")
    print(f"  - Skipped samples: {skipped}")
    
    if len(samples) == 0:
        print("âŒ No valid samples found!")
        return
    
    # Ø­Ø§Ù„Ø§ Ø³Ø¹ÛŒ Ú©Ù†ÛŒÙ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯/Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†ÛŒÙ…
    print("\nğŸ“¥ Processing audio files...")
    
    processed_samples = []
    
    for sample_info in tqdm(samples[:10], desc="Testing audio"):  # ÙÙ‚Ø· 10 Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
        idx = sample_info['idx']
        
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ ØµÙˆØªÛŒ
            item = ds[idx]
            audio_data = item.get('audio')
            
            # Ø§Ú¯Ø± audio ÛŒÚ© path Ø§Ø³Øª
            if isinstance(audio_data, str):
                print(f"Audio is path: {audio_data}")
                # TODO: Ø¯Ø§Ù†Ù„ÙˆØ¯ ÛŒØ§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø² path
                
            # Ø§Ú¯Ø± audio ÛŒÚ© bytes Ø§Ø³Øª
            elif isinstance(audio_data, bytes):
                print(f"Audio is bytes (size: {len(audio_data)} bytes)")
                # Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Øª Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´
                temp_path = f"/tmp/temp_audio_{idx}.mp3"
                with open(temp_path, 'wb') as f:
                    f.write(audio_data)
                
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ WAV
                audio, sr = librosa.load(temp_path, sr=SR, mono=True)
                os.remove(temp_path)
                
                # Ù¾Ø±Ø¯Ø§Ø²Ø´
                audio, _ = librosa.effects.trim(audio, top_db=20)
                peak = np.abs(audio).max()
                if peak > 0:
                    audio = (0.95 / peak) * audio
                
                # Ø°Ø®ÛŒØ±Ù‡
                filename = f"sample_{idx:06d}.wav"
                filepath = os.path.join(OUT_WAV_DIR, filename)
                sf.write(filepath, audio, SR, subtype="PCM_16")
                
                processed_samples.append({
                    'path': filepath,
                    'text': sample_info['text']
                })
                
            # Ø§Ú¯Ø± audio ÛŒÚ© dict Ø§Ø³Øª
            elif isinstance(audio_data, dict):
                print(f"Audio is dict with keys: {audio_data.keys()}")
                
            else:
                print(f"Unknown audio type: {type(audio_data)}")
                
        except Exception as e:
            print(f"Error processing audio {idx}: {e}")
            continue
    
    print(f"\nâœ… Successfully processed {len(processed_samples)} samples")
    
    if len(processed_samples) > 0:
        # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ„ÛŒØ³Øª ØªØ³Øª
        with open(os.path.join(OUT_FL_DIR, "test_samples.txt"), "w", encoding="utf-8") as f:
            for sample in processed_samples:
                f.write(f"{sample['path']}|{sample['text']}\n")
        print(f"ğŸ“ Test filelist saved to {OUT_FL_DIR}/test_samples.txt")

if __name__ == "__main__":
    main()
